{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Detect.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"_0ECIZSx-cni","colab_type":"code","colab":{}},"source":["%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SMcGUWkL2yzX","colab_type":"code","outputId":"66216b33-037f-424d-ab5b-bbced730bf7a","executionInfo":{"status":"ok","timestamp":1591248269176,"user_tz":-330,"elapsed":1502590,"user":{"displayName":"HARDI TRIVEDI HARDI TRIVEDI","photoUrl":"","userId":"02229028015741715467"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9ZueMjkg-gOF","colab_type":"code","outputId":"ed128166-5b2d-47b9-bdb3-1db4b7b42b19","executionInfo":{"status":"ok","timestamp":1591248270464,"user_tz":-330,"elapsed":1503874,"user":{"displayName":"HARDI TRIVEDI HARDI TRIVEDI","photoUrl":"","userId":"02229028015741715467"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd '/content/drive/My Drive/Colab Notebooks/faceswap'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1g2UuBsa9UDlyjlD0gRIML-BtsSk1Hwsv/Colab Notebooks/faceswap\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_5YPoBA9-ki5","colab_type":"code","outputId":"8b5d6539-02a4-4669-c2e3-93a1babb3415","executionInfo":{"status":"ok","timestamp":1591248299854,"user_tz":-330,"elapsed":1533259,"user":{"displayName":"HARDI TRIVEDI HARDI TRIVEDI","photoUrl":"","userId":"02229028015741715467"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python Faceforensics.py -d all -c c23 -t videos new --num_videos 10"],"execution_count":0,"outputs":[{"output_type":"stream","text":["By pressing any key to continue you confirm that you have agreed to the FaceForensics terms of use as described at:\n","http://canis.vc.in.tum.de:8100/webpage/FaceForensics_TOS.pdf\n","***\n","Press any key to continue, or CTRL-C to exit.\n","\n","Downloading videos of dataset \"original_sequences/youtube\"\n","Downloading the first 10 videos\n","Output path: new/original_sequences/youtube/c23/videos\n","WARNING: skipping download of existing file new/original_sequences/youtube/c23/videos/585.mp4\n","WARNING: skipping download of existing file new/original_sequences/youtube/c23/videos/599.mp4\n","WARNING: skipping download of existing file new/original_sequences/youtube/c23/videos/469.mp4\n","WARNING: skipping download of existing file new/original_sequences/youtube/c23/videos/481.mp4\n","WARNING: skipping download of existing file new/original_sequences/youtube/c23/videos/183.mp4\n","WARNING: skipping download of existing file new/original_sequences/youtube/c23/videos/253.mp4\n","WARNING: skipping download of existing file new/original_sequences/youtube/c23/videos/672.mp4\n","WARNING: skipping download of existing file new/original_sequences/youtube/c23/videos/720.mp4\n","WARNING: skipping download of existing file new/original_sequences/youtube/c23/videos/866.mp4\n","WARNING: skipping download of existing file new/original_sequences/youtube/c23/videos/878.mp4\n","100% 10/10 [00:00<00:00, 34.93it/s]\n","Downloading videos of dataset \"original_sequences/actors\"\n","Downloading the first 10 videos\n","Output path: new/original_sequences/actors/c23/videos\n","WARNING: skipping download of existing file new/original_sequences/actors/c23/videos/07__talking_against_wall.mp4\n","WARNING: skipping download of existing file new/original_sequences/actors/c23/videos/09__walking_down_street_outside_angry.mp4\n","WARNING: skipping download of existing file new/original_sequences/actors/c23/videos/13__talking_against_wall.mp4\n","WARNING: skipping download of existing file new/original_sequences/actors/c23/videos/13__walking_down_indoor_hall_disgust.mp4\n","WARNING: skipping download of existing file new/original_sequences/actors/c23/videos/18__kitchen_pan.mp4\n","WARNING: skipping download of existing file new/original_sequences/actors/c23/videos/27__kitchen_pan.mp4\n","WARNING: skipping download of existing file new/original_sequences/actors/c23/videos/06__outside_talking_still_laughing.mp4\n","WARNING: skipping download of existing file new/original_sequences/actors/c23/videos/01__kitchen_pan.mp4\n","WARNING: skipping download of existing file new/original_sequences/actors/c23/videos/08__podium_speech_happy.mp4\n","WARNING: skipping download of existing file new/original_sequences/actors/c23/videos/08__talking_against_wall.mp4\n","100% 10/10 [00:00<00:00, 35.47it/s]\n","Downloading videos of dataset \"manipulated_sequences/Deepfakes\"\n","Downloading the first 10 videos\n","Output path: new/manipulated_sequences/Deepfakes/c23/videos\n","WARNING: skipping download of existing file new/manipulated_sequences/Deepfakes/c23/videos/585_599.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/Deepfakes/c23/videos/599_585.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/Deepfakes/c23/videos/469_481.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/Deepfakes/c23/videos/481_469.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/Deepfakes/c23/videos/183_253.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/Deepfakes/c23/videos/253_183.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/Deepfakes/c23/videos/672_720.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/Deepfakes/c23/videos/720_672.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/Deepfakes/c23/videos/866_878.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/Deepfakes/c23/videos/878_866.mp4\n","100% 10/10 [00:00<00:00, 29.07it/s]\n","Downloading videos of dataset \"manipulated_sequences/DeepFakeDetection\"\n","Downloading the first 10 videos\n","Output path: new/manipulated_sequences/DeepFakeDetection/c23/videos\n","WARNING: skipping download of existing file new/manipulated_sequences/DeepFakeDetection/c23/videos/01_11__talking_against_wall__9229VVZ3.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/DeepFakeDetection/c23/videos/13_03__exit_phone_room__GBYWJW06.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/DeepFakeDetection/c23/videos/18_04__walking_outside_cafe_disgusted__6J3ZFEJQ.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/DeepFakeDetection/c23/videos/06_04__walking_outside_cafe_disgusted__ZK95PQDE.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/DeepFakeDetection/c23/videos/04_06__kitchen_still__ZK95PQDE.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/DeepFakeDetection/c23/videos/03_11__talking_against_wall__P08VGHTA.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/DeepFakeDetection/c23/videos/21_09__walking_outside_cafe_disgusted__Z8H2TRCI.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/DeepFakeDetection/c23/videos/22_23__outside_talking_still_laughing__W9MT3Q5K.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/DeepFakeDetection/c23/videos/20_27__kitchen_pan__LM907ECA.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/DeepFakeDetection/c23/videos/10_22__kitchen_pan__EHARPYBT.mp4\n","100% 10/10 [00:00<00:00, 35.30it/s]\n","Downloading videos of dataset \"manipulated_sequences/Face2Face\"\n","Downloading the first 10 videos\n","Output path: new/manipulated_sequences/Face2Face/c23/videos\n","WARNING: skipping download of existing file new/manipulated_sequences/Face2Face/c23/videos/585_599.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/Face2Face/c23/videos/599_585.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/Face2Face/c23/videos/469_481.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/Face2Face/c23/videos/481_469.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/Face2Face/c23/videos/183_253.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/Face2Face/c23/videos/253_183.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/Face2Face/c23/videos/672_720.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/Face2Face/c23/videos/720_672.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/Face2Face/c23/videos/866_878.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/Face2Face/c23/videos/878_866.mp4\n","100% 10/10 [00:00<00:00, 36.96it/s]\n","Downloading videos of dataset \"manipulated_sequences/FaceSwap\"\n","Downloading the first 10 videos\n","Output path: new/manipulated_sequences/FaceSwap/c23/videos\n","WARNING: skipping download of existing file new/manipulated_sequences/FaceSwap/c23/videos/585_599.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/FaceSwap/c23/videos/599_585.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/FaceSwap/c23/videos/469_481.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/FaceSwap/c23/videos/481_469.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/FaceSwap/c23/videos/183_253.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/FaceSwap/c23/videos/253_183.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/FaceSwap/c23/videos/672_720.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/FaceSwap/c23/videos/720_672.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/FaceSwap/c23/videos/866_878.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/FaceSwap/c23/videos/878_866.mp4\n","100% 10/10 [00:00<00:00, 17.77it/s]\n","Downloading videos of dataset \"manipulated_sequences/NeuralTextures\"\n","Downloading the first 10 videos\n","Output path: new/manipulated_sequences/NeuralTextures/c23/videos\n","WARNING: skipping download of existing file new/manipulated_sequences/NeuralTextures/c23/videos/585_599.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/NeuralTextures/c23/videos/599_585.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/NeuralTextures/c23/videos/469_481.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/NeuralTextures/c23/videos/481_469.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/NeuralTextures/c23/videos/183_253.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/NeuralTextures/c23/videos/253_183.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/NeuralTextures/c23/videos/672_720.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/NeuralTextures/c23/videos/720_672.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/NeuralTextures/c23/videos/866_878.mp4\n","WARNING: skipping download of existing file new/manipulated_sequences/NeuralTextures/c23/videos/878_866.mp4\n","100% 10/10 [00:00<00:00, 39.25it/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YsK8q04h-r59","colab_type":"code","outputId":"2cf3c1f4-6fde-4763-a4fd-506c4b4a4585","executionInfo":{"status":"ok","timestamp":1591248885186,"user_tz":-330,"elapsed":4771,"user":{"displayName":"HARDI TRIVEDI HARDI TRIVEDI","photoUrl":"","userId":"02229028015741715467"}},"colab":{"base_uri":"https://localhost:8080/","height":776}},"source":["!pip install -r classification/requirements1.txt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: absl-py==0.4.0 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 1)) (0.4.0)\n","Requirement already satisfied: astor==0.7.1 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 2)) (0.7.1)\n","Requirement already satisfied: certifi==2018.11.29 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 3)) (2018.11.29)\n","Requirement already satisfied: cffi==1.12.1 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 4)) (1.12.1)\n","Requirement already satisfied: cmake==3.12.0 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 5)) (3.12.0)\n","Requirement already satisfied: dlib in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 6)) (19.18.0)\n","Requirement already satisfied: face-recognition==1.2.3 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 7)) (1.2.3)\n","Requirement already satisfied: face-recognition-models==0.3.0 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 8)) (0.3.0)\n","Requirement already satisfied: ffmpy==0.2.2 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 9)) (0.2.2)\n","Requirement already satisfied: gast==0.2.0 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 10)) (0.2.0)\n","Requirement already satisfied: grpcio==1.14.1 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 11)) (1.14.1)\n","Requirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 12)) (2.8.0)\n","Requirement already satisfied: Keras==2.2.0 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 13)) (2.2.0)\n","Requirement already satisfied: Markdown==2.6.11 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 14)) (2.6.11)\n","Requirement already satisfied: mkl-fft in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 15)) (1.0.6)\n","Requirement already satisfied: mkl-random in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 16)) (1.0.1.1)\n","Requirement already satisfied: munch==2.3.2 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 17)) (2.3.2)\n","Requirement already satisfied: numpy==1.16.2 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 18)) (1.16.2)\n","Requirement already satisfied: nvidia-ml-py3==7.352.0 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 19)) (7.352.0)\n","Requirement already satisfied: olefile==0.46 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 20)) (0.46)\n","Requirement already satisfied: opencv-python==3.4.1.15 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 21)) (3.4.1.15)\n","Requirement already satisfied: pathlib==1.0.1 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 22)) (1.0.1)\n","Requirement already satisfied: Pillow==5.4.1 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 23)) (5.4.1)\n","Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 24)) (0.7.4)\n","Requirement already satisfied: protobuf==3.6.1 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 25)) (3.6.1)\n","Requirement already satisfied: pycparser==2.19 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 26)) (2.19)\n","Requirement already satisfied: scandir==1.7 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 27)) (1.7)\n","Requirement already satisfied: six==1.12.0 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 28)) (1.12.0)\n","Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 29)) (1.1.0)\n","Requirement already satisfied: torch==1.0.1.post2 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 30)) (1.0.1.post2)\n","Requirement already satisfied: torchvision==0.2.1 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 31)) (0.2.1)\n","Requirement already satisfied: tqdm==4.25.0 in /usr/local/lib/python3.6/dist-packages (from -r classification/requirements1.txt (line 32)) (4.25.0)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face-recognition==1.2.3->-r classification/requirements1.txt (line 7)) (7.1.2)\n","Requirement already satisfied: keras-applications==1.0.2 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.0->-r classification/requirements1.txt (line 13)) (1.0.2)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.0->-r classification/requirements1.txt (line 13)) (1.4.1)\n","Requirement already satisfied: keras-preprocessing==1.0.1 in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.0->-r classification/requirements1.txt (line 13)) (1.0.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras==2.2.0->-r classification/requirements1.txt (line 13)) (3.13)\n","Requirement already satisfied: intel-numpy in /usr/local/lib/python3.6/dist-packages (from mkl-fft->-r classification/requirements1.txt (line 15)) (1.15.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf==3.6.1->-r classification/requirements1.txt (line 25)) (47.1.1)\n","Requirement already satisfied: icc-rt in /usr/local/lib/python3.6/dist-packages (from intel-numpy->mkl-fft->-r classification/requirements1.txt (line 15)) (2020.0.133)\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.6/dist-packages (from intel-numpy->mkl-fft->-r classification/requirements1.txt (line 15)) (2019.0)\n","Requirement already satisfied: mkl in /usr/local/lib/python3.6/dist-packages (from intel-numpy->mkl-fft->-r classification/requirements1.txt (line 15)) (2019.0)\n","Requirement already satisfied: intel-openmp==2020.* in /usr/local/lib/python3.6/dist-packages (from icc-rt->intel-numpy->mkl-fft->-r classification/requirements1.txt (line 15)) (2020.0.133)\n","Requirement already satisfied: tbb==2019.* in /usr/local/lib/python3.6/dist-packages (from tbb4py->intel-numpy->mkl-fft->-r classification/requirements1.txt (line 15)) (2019.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RLc88fz2K5ZP","colab_type":"code","outputId":"d9bcfe3c-008e-4ba1-c54f-a2e2fa0c8fa8","executionInfo":{"status":"ok","timestamp":1591248898446,"user_tz":-330,"elapsed":8109,"user":{"displayName":"HARDI TRIVEDI HARDI TRIVEDI","photoUrl":"","userId":"02229028015741715467"}},"colab":{"base_uri":"https://localhost:8080/","height":252}},"source":["!python classification/detect_from_video.py -h"],"execution_count":0,"outputs":[{"output_type":"stream","text":["usage: detect_from_video.py [-h] [--video_path VIDEO_PATH]\n","                            [--model_path MODEL_PATH]\n","                            [--output_path OUTPUT_PATH]\n","                            [--start_frame START_FRAME]\n","                            [--end_frame END_FRAME] [--cuda]\n","\n","optional arguments:\n","  -h, --help            show this help message and exit\n","  --video_path VIDEO_PATH, -i VIDEO_PATH\n","  --model_path MODEL_PATH, -mi MODEL_PATH\n","  --output_path OUTPUT_PATH, -o OUTPUT_PATH\n","  --start_frame START_FRAME\n","  --end_frame END_FRAME\n","  --cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q3oYb3nlH33B","colab_type":"code","outputId":"fae3496f-35d1-4968-8312-cec0985e4dc6","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1591259501622,"user_tz":-330,"elapsed":40718,"user":{"displayName":"HARDI TRIVEDI HARDI TRIVEDI","photoUrl":"","userId":"02229028015741715467"}}},"source":["!python classification/detect_from_video.py -i downloaded_faceforensics_videos/original_sequences/youtube/c23/videos -m classification/faceforensics++_models/full/xception/full_c23.p -o output_path/detection"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Starting: downloaded_faceforensics_videos/original_sequences/youtube/c23/videos/585.mp4\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'network.models.TransferModel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'pretrainedmodels.models.xception.Xception' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'pretrainedmodels.models.xception.Block' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'pretrainedmodels.models.xception.SeparableConv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 359/359 [06:46<00:00,  1.13s/it]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/original_sequences/youtube/c23/videos/599.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 398/398 [07:29<00:00,  1.14s/it]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/original_sequences/youtube/c23/videos/469.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 414/414 [05:51<00:00,  1.18it/s]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/original_sequences/youtube/c23/videos/481.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 414/414 [07:48<00:00,  1.13s/it]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/original_sequences/youtube/c23/videos/183.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 390/390 [07:24<00:00,  1.18s/it]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/original_sequences/youtube/c23/videos/253.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 501/501 [09:33<00:00,  1.12s/it]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/original_sequences/youtube/c23/videos/672.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 541/541 [10:19<00:00,  1.14s/it]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/original_sequences/youtube/c23/videos/720.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 564/564 [07:33<00:00,  3.44it/s]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/original_sequences/youtube/c23/videos/866.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 509/509 [15:00<00:00,  1.76s/it]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/original_sequences/youtube/c23/videos/878.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 736/736 [13:57<00:00,  1.13s/it]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/original_sequences/youtube/c23/videos/339.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 457/457 [06:07<00:00,  1.25it/s]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/original_sequences/youtube/c23/videos/392.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 1496/1496 [28:23<00:00,  1.15s/it]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/original_sequences/youtube/c23/videos/828.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 319/319 [04:25<00:00,  1.19it/s]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/original_sequences/youtube/c23/videos/830.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 511/511 [06:50<00:00,  1.25it/s]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/original_sequences/youtube/c23/videos/252.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 572/572 [08:03<00:00,  1.18it/s]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/original_sequences/youtube/c23/videos/266.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 465/465 [06:21<00:00,  1.23it/s]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/original_sequences/youtube/c23/videos/033.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n"," 64% 514/809 [07:20<04:12,  1.17it/s]Traceback (most recent call last):\n","  File \"classification/detect_from_video.py\", line 239, in <module>\n","    test_full_image_network(**vars(args))\n","  File \"classification/detect_from_video.py\", line 187, in test_full_image_network\n","    cuda=cuda)\n","  File \"classification/detect_from_video.py\", line 95, in predict_with_model\n","    output = model(preprocessed_image)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 489, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/drive/.shortcut-targets-by-id/1g2UuBsa9UDlyjlD0gRIML-BtsSk1Hwsv/Colab Notebooks/faceswap/classification/network/models.py\", line 114, in forward\n","    x = self.model(x)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 489, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/pretrainedmodels/models/xception.py\", line 210, in forward\n","    x = self.features(input)\n","  File \"/usr/local/lib/python3.6/dist-packages/pretrainedmodels/models/xception.py\", line 182, in features\n","    x = self.block3(x)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 489, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/pretrainedmodels/models/xception.py\", line 103, in forward\n","    x = self.rep(inp)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 489, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\", line 92, in forward\n","    input = module(input)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 489, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/pretrainedmodels/models/xception.py\", line 59, in forward\n","    x = self.pointwise(x)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 489, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\", line 320, in forward\n","    self.padding, self.dilation, self.groups)\n","KeyboardInterrupt\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rp56yqNUmkFF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"a5afba72-2d45-4937-c136-208eee5dcf89","executionInfo":{"status":"ok","timestamp":1591265868749,"user_tz":-330,"elapsed":3801897,"user":{"displayName":"HARDI TRIVEDI HARDI TRIVEDI","photoUrl":"","userId":"02229028015741715467"}}},"source":["!python classification/detect_from_video.py -i downloaded_faceforensics_videos/manipulated_sequences/Face2Face/c23/videos -m classification/faceforensics++_models/full/xception/full_c23.p -o output_path/detection"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Starting: downloaded_faceforensics_videos/manipulated_sequences/Face2Face/c23/videos/033_097.mp4\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'network.models.TransferModel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'pretrainedmodels.models.xception.Xception' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'pretrainedmodels.models.xception.Block' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'pretrainedmodels.models.xception.SeparableConv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n","  warnings.warn(msg, SourceChangeWarning)\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 478/478 [06:52<00:00,  1.17it/s]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/manipulated_sequences/Face2Face/c23/videos/585_599.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 398/398 [07:35<00:00,  1.14s/it]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/manipulated_sequences/Face2Face/c23/videos/599_585.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 359/359 [06:48<00:00,  1.13s/it]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/manipulated_sequences/Face2Face/c23/videos/469_481.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 414/414 [05:52<00:00,  1.17it/s]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/manipulated_sequences/Face2Face/c23/videos/481_469.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 414/414 [07:52<00:00,  1.14s/it]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/manipulated_sequences/Face2Face/c23/videos/183_253.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 501/501 [09:31<00:00,  1.14s/it]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/manipulated_sequences/Face2Face/c23/videos/253_183.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 390/390 [07:25<00:00,  1.13s/it]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/manipulated_sequences/Face2Face/c23/videos/672_720.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","100% 564/564 [10:42<00:00,  1.13s/it]\n","Finished! Output saved under output_path/detection\n","Starting: downloaded_faceforensics_videos/manipulated_sequences/Face2Face/c23/videos/720_672.mp4\n","Model found in classification/faceforensics++_models/full/xception/full_c23.p\n","  0% 2/541 [00:00<03:37,  2.48it/s]\n","  3% 16/541 [00:12<07:24,  1.18it/s]Traceback (most recent call last):\n","  File \"classification/detect_from_video.py\", line 239, in <module>\n","    test_full_image_network(**vars(args))\n","  File \"classification/detect_from_video.py\", line 187, in test_full_image_network\n","    cuda=cuda)\n","  File \"classification/detect_from_video.py\", line 95, in predict_with_model\n","    output = model(preprocessed_image)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 489, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/drive/.shortcut-targets-by-id/1g2UuBsa9UDlyjlD0gRIML-BtsSk1Hwsv/Colab Notebooks/faceswap/classification/network/models.py\", line 114, in forward\n","    x = self.model(x)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 489, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/pretrainedmodels/models/xception.py\", line 210, in forward\n","    x = self.features(input)\n","  File \"/usr/local/lib/python3.6/dist-packages/pretrainedmodels/models/xception.py\", line 189, in features\n","    x = self.block10(x)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 489, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/pretrainedmodels/models/xception.py\", line 103, in forward\n","    x = self.rep(inp)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 489, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\", line 92, in forward\n","    input = module(input)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 489, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\", line 76, in forward\n","    exponential_average_factor, self.eps)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\", line 1623, in batch_norm\n","    training, momentum, eps, torch.backends.cudnn.enabled\n","KeyboardInterrupt\n","\n"],"name":"stdout"}]}]}