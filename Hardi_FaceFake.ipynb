{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FaceFake.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"vy1XVXbWDOcP","colab_type":"code","outputId":"d676d96e-13eb-4d7a-c20c-044e447cb6a6","executionInfo":{"status":"ok","timestamp":1591164393691,"user_tz":-330,"elapsed":18984,"user":{"displayName":"Hardi Trivedi","photoUrl":"https://lh5.googleusercontent.com/-KiuyDj-DCbs/AAAAAAAAAAI/AAAAAAAAPbo/R0GSg7b3cbM/s64/photo.jpg","userId":"03163205148644422257"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dpBCwf-yEG4B","colab_type":"code","outputId":"bb8f4d20-b69b-4d15-9e72-2e33ee765f7b","executionInfo":{"status":"ok","timestamp":1591164397799,"user_tz":-330,"elapsed":901,"user":{"displayName":"Hardi Trivedi","photoUrl":"https://lh5.googleusercontent.com/-KiuyDj-DCbs/AAAAAAAAAAI/AAAAAAAAPbo/R0GSg7b3cbM/s64/photo.jpg","userId":"03163205148644422257"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd 'drive/My Drive/Colab Notebooks/faceswap'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/faceswap\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FCOy096YFlkk","colab_type":"code","outputId":"74a82641-dc08-4c98-860e-f6eed2dc577d","executionInfo":{"status":"ok","timestamp":1591161765825,"user_tz":-330,"elapsed":66789,"user":{"displayName":"Hardi Trivedi","photoUrl":"https://lh5.googleusercontent.com/-KiuyDj-DCbs/AAAAAAAAAAI/AAAAAAAAPbo/R0GSg7b3cbM/s64/photo.jpg","userId":"03163205148644422257"}},"colab":{"base_uri":"https://localhost:8080/","height":790}},"source":["%run setup.py"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[32mINFO   \u001b[0m Running as Root/Admin\n","\u001b[32mINFO   \u001b[0m The tool provides tips for installation\r\n","        and installs required python packages\n","\u001b[32mINFO   \u001b[0m Setup in Linux 4.19.104+\n","\u001b[32mINFO   \u001b[0m Installed Python: 3.6.9 64bit\n","\u001b[32mINFO   \u001b[0m Encoding: UTF-8\n","\u001b[32mINFO   \u001b[0m Upgrading pip...\n","\u001b[32mINFO   \u001b[0m Installed pip: 19.3.1\n","\u001b[32mINFO   \u001b[0m AMD Support: AMD GPU support is currently limited.\n","        Nvidia Users MUST answer 'no' to this option.\n","Enable AMD Support? [y/N] n\n","Enable  Docker? [y/N] n\n","\u001b[32mINFO   \u001b[0m AMD Support Disabled\n","\u001b[32mINFO   \u001b[0m Docker Disabled\n","Enable  CUDA? [Y/n] y\n","\u001b[32mINFO   \u001b[0m CUDA Enabled\n","\u001b[32mINFO   \u001b[0m CUDA version: 10.1\n","\u001b[32mINFO   \u001b[0m cuDNN version: 7.6.5\n","\u001b[33mWARNING\u001b[0m The minimum Tensorflow requirement is 1.12. \n","        Tensorflow currently has no official prebuild for your CUDA, cuDNN combination.\n","        Either install a combination that Tensorflow supports or build and install your own tensorflow-gpu.\n","        CUDA Version: 10.1\n","        cuDNN Version: 7.6\n","        Help:\n","        Building Tensorflow: https://www.tensorflow.org/install/install_sources\n","        Tensorflow supported versions: https://www.tensorflow.org/install/source#tested_build_configurations\n","Location of custom tensorflow-gpu wheel (leave blank to manually install): \n","\u001b[32mINFO   \u001b[0m Faceswap config written to: /content/drive/My Drive/Colab Notebooks/faceswap/config/.faceswap\n","Please ensure your System Dependencies are met. Continue? [y/N] y\n","\u001b[32mINFO   \u001b[0m Installing Required Python Packages. This may take some time...\n","\u001b[32mINFO   \u001b[0m Installing numpy==1.17.4\n","\u001b[32mINFO   \u001b[0m Installing Pillow==6.2.1\n","\u001b[32mINFO   \u001b[0m Installing toposort\n","\u001b[32mINFO   \u001b[0m Installing fastcluster\n","\u001b[32mINFO   \u001b[0m Installing matplotlib==3.1.1\n","\u001b[32mINFO   \u001b[0m Installing imageio==2.6.1\n","\u001b[32mINFO   \u001b[0m Installing imageio-ffmpeg\n","\u001b[32mINFO   \u001b[0m Installing ffmpy==0.2.2\n","\u001b[32mINFO   \u001b[0m Installing git+https://github.com/deepfakes/nvidia-ml-py3.git\n","\u001b[32mINFO   \u001b[0m Installing h5py==2.9.0\n","\u001b[32mINFO   \u001b[0m Installing Keras==2.2.4\n","\u001b[32mINFO   \u001b[0m All python3 dependencies are met.\n","        You are good to go.\n","        \n","        Enter:  'python faceswap.py -h' to see the options\n","                'python faceswap.py gui' to launch the GUI\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tQTq6pXBF9CT","colab_type":"code","outputId":"fca5df79-ce7a-42ca-bc92-cad1fa1155e8","executionInfo":{"status":"ok","timestamp":1591161817218,"user_tz":-330,"elapsed":8232,"user":{"displayName":"Hardi Trivedi","photoUrl":"https://lh5.googleusercontent.com/-KiuyDj-DCbs/AAAAAAAAAAI/AAAAAAAAPbo/R0GSg7b3cbM/s64/photo.jpg","userId":"03163205148644422257"}},"colab":{"base_uri":"https://localhost:8080/","height":286}},"source":["!pip install gast==0.2.2"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting gast==0.2.2\n","  Downloading gast-0.2.2.tar.gz (10 kB)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7539 sha256=7dc468c5ab2a3c3607d3d0f4c4e67139ef85e76e79e263484cae1ae3927cbe1f\n","  Stored in directory: /root/.cache/pip/wheels/19/a7/b9/0740c7a3a7d1d348f04823339274b90de25fbcd217b2ee1fbe\n","Successfully built gast\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement h5py<2.11.0,>=2.10.0, but you'll have h5py 2.9.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: gast\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","Successfully installed gast-0.2.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8CDWy7jIkxvq","colab_type":"code","outputId":"c02a34eb-006a-4bd8-a91c-a90df10acfd6","executionInfo":{"status":"ok","timestamp":1591161823463,"user_tz":-330,"elapsed":13280,"user":{"displayName":"Hardi Trivedi","photoUrl":"https://lh5.googleusercontent.com/-KiuyDj-DCbs/AAAAAAAAAAI/AAAAAAAAPbo/R0GSg7b3cbM/s64/photo.jpg","userId":"03163205148644422257"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["!pip install folium==0.2.1"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting folium==0.2.1\n","  Downloading folium-0.2.1.tar.gz (69 kB)\n","\u001b[?25l\r\u001b[K     |████▊                           | 10 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 20 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 30 kB 37.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 40 kB 27.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 51 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 61 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 69 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: Jinja2 in /usr/local/lib/python3.6/dist-packages (from folium==0.2.1) (2.11.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2->folium==0.2.1) (1.1.1)\n","Building wheels for collected packages: folium\n","  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for folium: filename=folium-0.2.1-py3-none-any.whl size=79978 sha256=4101ae8df63b08f84a76566fb57505cee427a24a46cad793f0bd355a697d66ad\n","  Stored in directory: /root/.cache/pip/wheels/b9/9d/f7/42a080a41839b2db3c3572a0c81cc17a88a7f4ba890741c621\n","Successfully built folium\n","Installing collected packages: folium\n","  Attempting uninstall: folium\n","    Found existing installation: folium 0.8.3\n","    Uninstalling folium-0.8.3:\n","      Successfully uninstalled folium-0.8.3\n","Successfully installed folium-0.2.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kXr6UXRL7MZy","colab_type":"code","outputId":"f397ded7-b4ba-4ade-9d9c-a8dca7a25491","executionInfo":{"status":"ok","timestamp":1591161831697,"user_tz":-330,"elapsed":19997,"user":{"displayName":"Hardi Trivedi","photoUrl":"https://lh5.googleusercontent.com/-KiuyDj-DCbs/AAAAAAAAAAI/AAAAAAAAPbo/R0GSg7b3cbM/s64/photo.jpg","userId":"03163205148644422257"}},"colab":{"base_uri":"https://localhost:8080/","height":507}},"source":["!pip install imgaug==0.2.6"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting imgaug==0.2.6\n","  Downloading imgaug-0.2.6.tar.gz (631 kB)\n","\u001b[?25l\r\u001b[K     |▌                               | 10 kB 30.5 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 35.2 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 30 kB 39.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 61 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 92 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 102 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 112 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 122 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 133 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 143 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 153 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 163 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 174 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 184 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 194 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 204 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 215 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 225 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 235 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 245 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 256 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 266 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 276 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 286 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 296 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 307 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 317 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 327 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 337 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 348 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 358 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 368 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 378 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 389 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 399 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 409 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 419 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 430 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 440 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 450 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 460 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 471 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 481 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 491 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 501 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 512 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 522 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 532 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 542 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 552 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 563 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 573 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 583 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 593 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 604 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 614 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 624 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 631 kB 12.6 MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.6) (1.4.1)\n","Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.6) (0.16.2)\n","Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.6) (1.17.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug==0.2.6) (1.12.0)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (2.4)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (2.6.1)\n","Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (6.2.1)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (1.1.1)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6) (3.1.1)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug==0.2.6) (4.4.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.6) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.6) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.6) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.6) (2.8.1)\n","Building wheels for collected packages: imgaug\n","  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for imgaug: filename=imgaug-0.2.6-py3-none-any.whl size=654018 sha256=eab6ca0b1a2b70a12c6005418ba79ed573187c8fd5d37c88355f4928e5b8bf11\n","  Stored in directory: /root/.cache/pip/wheels/ce/b4/ea/ed7e89421721d66834627a2983c5bc4ce298056d5d3f37049e\n","Successfully built imgaug\n","Installing collected packages: imgaug\n","  Attempting uninstall: imgaug\n","    Found existing installation: imgaug 0.2.9\n","    Uninstalling imgaug-0.2.9:\n","      Successfully uninstalled imgaug-0.2.9\n","Successfully installed imgaug-0.2.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LcStZMkF7cRJ","colab_type":"code","outputId":"600564bb-5039-437e-ad72-9ccb58299ed7","executionInfo":{"status":"ok","timestamp":1591161831700,"user_tz":-330,"elapsed":18221,"user":{"displayName":"Hardi Trivedi","photoUrl":"https://lh5.googleusercontent.com/-KiuyDj-DCbs/AAAAAAAAAAI/AAAAAAAAPbo/R0GSg7b3cbM/s64/photo.jpg","userId":"03163205148644422257"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%tensorflow_version 1.x"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JC9Ci_EK7i2s","colab_type":"code","outputId":"b0c008c9-d8d5-4380-b409-ab6582b556ef","executionInfo":{"status":"ok","timestamp":1590944178659,"user_tz":-330,"elapsed":17564,"user":{"displayName":"Hardi Trivedi","photoUrl":"https://lh5.googleusercontent.com/-KiuyDj-DCbs/AAAAAAAAAAI/AAAAAAAAPbo/R0GSg7b3cbM/s64/photo.jpg","userId":"03163205148644422257"}},"colab":{"base_uri":"https://localhost:8080/","height":252}},"source":["!python faceswap.py -h"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Setting Faceswap backend to NVIDIA\n","usage: faceswap.py [-h] {extract,train,convert,gui} ...\n","\n","positional arguments:\n","  {extract,train,convert,gui}\n","    extract             Extract the faces from pictures\n","    train               This command trains the model for the two faces A and\n","                        B\n","    convert             Convert a source image to a new one with the face\n","                        swapped\n","    gui                 Launch the Faceswap Graphical User Interface\n","\n","optional arguments:\n","  -h, --help            show this help message and exit\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hTKFau9F7ps2","colab_type":"code","outputId":"8e7e2f7b-7e1c-47e6-b59f-2b98c40bcabc","executionInfo":{"status":"ok","timestamp":1590944183338,"user_tz":-330,"elapsed":20962,"user":{"displayName":"Hardi Trivedi","photoUrl":"https://lh5.googleusercontent.com/-KiuyDj-DCbs/AAAAAAAAAAI/AAAAAAAAPbo/R0GSg7b3cbM/s64/photo.jpg","userId":"03163205148644422257"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python faceswap.py extract -h"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Setting Faceswap backend to NVIDIA\n","usage: faceswap.py extract [-h] [-C CONFIGFILE]\n","                           [-L {INFO,VERBOSE,DEBUG,TRACE}] [-LF LOGFILE] -i\n","                           INPUT_DIR -o OUTPUT_DIR [-al ALIGNMENTS_PATH]\n","                           [-D {cv2-dnn,mtcnn,s3fd}] [-A {cv2-dnn,fan}]\n","                           [-M {unet-dfl,vgg-clear,vgg-obstructed} [{unet-dfl,vgg-clear,vgg-obstructed} ...]]\n","                           [-nm {none,clahe,hist,mean}] [-r ROTATE_IMAGES]\n","                           [-min MIN_SIZE] [-n NFILTER [NFILTER ...]]\n","                           [-f FILTER [FILTER ...]] [-l REF_THRESHOLD]\n","                           [-een EXTRACT_EVERY_N] [-sz SIZE]\n","                           [-si SAVE_INTERVAL] [-dl] [-sp] [-s] [-sf] [-ssf]\n","\n","Extract the faces from pictures\n","\n","optional arguments:\n","  -h, --help            show this help message and exit\n","  -C CONFIGFILE, --configfile CONFIGFILE\n","                        Optionally overide the saved config with the path to a\n","                        custom config file.\n","  -L {INFO,VERBOSE,DEBUG,TRACE}, --loglevel {INFO,VERBOSE,DEBUG,TRACE}\n","                        Log level. Stick with INFO or VERBOSE unless you need\n","                        to file an error report. Be careful with TRACE as it\n","                        will generate a lot of data\n","  -LF LOGFILE, --logfile LOGFILE\n","                        Path to store the logfile. Leave blank to store in the\n","                        faceswap folder\n","  -i INPUT_DIR, --input-dir INPUT_DIR\n","                        Input directory or video. Either a directory\n","                        containing the image files you wish to process or path\n","                        to a video file. NB: This should be the source\n","                        video/frames NOT the source faces.\n","  -o OUTPUT_DIR, --output-dir OUTPUT_DIR\n","                        Output directory. This is where the converted files\n","                        will be saved.\n","  -al ALIGNMENTS_PATH, --alignments ALIGNMENTS_PATH\n","                        Optional path to an alignments file. Leave blank if\n","                        the alignments file is at the default location.\n","  -D {cv2-dnn,mtcnn,s3fd}, --detector {cv2-dnn,mtcnn,s3fd}\n","                        Detector to use. Some of these have configurable\n","                        settings in '/config/extract.ini' or 'Settings >\n","                        Configure Extract 'Plugins':\n","                          - cv2-dnn: A CPU only extractor which is the least\n","                            reliable and least resource intensive. Use this if\n","                            not using a GPU and time is important.\n","                          - mtcnn: Good detector. Fast on CPU, faster on GPU.\n","                            Uses fewer resources than other GPU detectors but\n","                            can often return more false positives.\n","                          - s3fd: Best detector. Fast on GPU, slow on CPU. Can\n","                            detect more faces and fewer false positives than\n","                            other GPU detectors, but is a lot more resource\n","                            intensive.\n","  -A {cv2-dnn,fan}, --aligner {cv2-dnn,fan}\n","                        Aligner to use.\n","                          - cv2-dnn: A CPU only landmark detector. Faster,\n","                            less resource intensive, but less accurate. Only\n","                            use this if not using a GPU and time is important.\n","                          - fan: Best aligner. Fast on GPU, slow on CPU.\n","  -M {unet-dfl,vgg-clear,vgg-obstructed} [{unet-dfl,vgg-clear,vgg-obstructed} ...], --masker {unet-dfl,vgg-clear,vgg-obstructed} [{unet-dfl,vgg-clear,vgg-obstructed} ...]\n","                        Additional Masker(s) to use. The masks generated here\n","                        will all take up GPU RAM. You can select none, one or\n","                        multiple masks, but the extraction may take longer the\n","                        more you select. NB: The Extended and Components\n","                        (landmark based) masks are automatically generated on\n","                        extraction.\n","                          - vgg-clear: Mask designed to provide smart\n","                            segmentation of mostly frontal faces clear of\n","                            obstructions. Profile faces and obstructions may\n","                            result in sub-par performance.\n","                          - vgg-obstructed: Mask designed to provide smart\n","                            segmentation of mostly frontal faces. The mask\n","                            model has been specifically trained to recognize\n","                            some facial obstructions (hands and eyeglasses).\n","                            Profile faces may result in sub-par performance.\n","                          - unet-dfl: Mask designed to provide smart\n","                            segmentation of mostly frontal faces. The mask\n","                            model has been trained by community members and\n","                            will need testing for further description. Profile\n","                            faces may result in sub-par performance.\n","                        The auto generated masks are as follows:\n","                          - components: Mask designed to provide facial\n","                            segmentation based on the positioning of landmark\n","                            locations. A convex hull is constructed around the\n","                            exterior of the landmarks to create a mask.\n","                          - extended: Mask designed to provide facial\n","                            segmentation based on the positioning of landmark\n","                            locations. A convex hull is constructed around the\n","                            exterior of the landmarks and the mask is extended\n","                            upwards onto the forehead.\n","                        (eg: `-M unet-dfl vgg-clear`, `--masker vgg-\n","                        obstructed`)\n","  -nm {none,clahe,hist,mean}, --normalization {none,clahe,hist,mean}\n","                        Performing normalization can help the aligner better\n","                        align faces with difficult lighting conditions at an\n","                        extraction speed cost. Different methods will yield\n","                        different results on different sets. NB: This does not\n","                        impact the output face, just the input to the aligner.\n","                          - none: Don't perform normalization on the face.\n","                          - clahe: Perform Contrast Limited Adaptive Histogram\n","                            Equalization on the face.\n","                          - hist: Equalize the histograms on the RGB channels.\n","                          - mean: Normalize the face colors to the mean.\n","  -r ROTATE_IMAGES, --rotate-images ROTATE_IMAGES\n","                        If a face isn't found, rotate the images to try to\n","                        find a face. Can find more faces at the cost of\n","                        extraction speed. Pass in a single number to use\n","                        increments of that size up to 360, or pass in a list\n","                        of numbers to enumerate exactly what angles to check.\n","  -min MIN_SIZE, --min-size MIN_SIZE\n","                        Filters out faces detected below this size. Length, in\n","                        pixels across the diagonal of the bounding box. Set to\n","                        0 for off\n","  -n NFILTER [NFILTER ...], --nfilter NFILTER [NFILTER ...]\n","                        Optionally filter out people who you do not wish to\n","                        process by passing in an image of that person. Should\n","                        be a front portrait with a single person in the image.\n","                        Multiple images can be added space separated. NB:\n","                        Using face filter will significantly decrease\n","                        extraction speed and its accuracy cannot be\n","                        guaranteed.\n","  -f FILTER [FILTER ...], --filter FILTER [FILTER ...]\n","                        Optionally select people you wish to process by\n","                        passing in an image of that person. Should be a front\n","                        portrait with a single person in the image. Multiple\n","                        images can be added space separated. NB: Using face\n","                        filter will significantly decrease extraction speed\n","                        and its accuracy cannot be guaranteed.\n","  -l REF_THRESHOLD, --ref_threshold REF_THRESHOLD\n","                        For use with the optional nfilter/filter files.\n","                        Threshold for positive face recognition. Lower values\n","                        are stricter. NB: Using face filter will significantly\n","                        decrease extraction speed and its accuracy cannot be\n","                        guaranteed.\n","  -een EXTRACT_EVERY_N, --extract-every-n EXTRACT_EVERY_N\n","                        Extract every 'nth' frame. This option will skip\n","                        frames when extracting faces. For example a value of 1\n","                        will extract faces from every frame, a value of 10\n","                        will extract faces from every 10th frame.\n","  -sz SIZE, --size SIZE\n","                        The output size of extracted faces. Make sure that the\n","                        model you intend to train supports your required size.\n","                        This will only need to be changed for hi-res models.\n","  -si SAVE_INTERVAL, --save-interval SAVE_INTERVAL\n","                        Automatically save the alignments file after a set\n","                        amount of frames. By default the alignments file is\n","                        only saved at the end of the extraction process. NB:\n","                        If extracting in 2 passes then the alignments file\n","                        will only start to be saved out during the second\n","                        pass. WARNING: Don't interrupt the script when writing\n","                        the file because it might get corrupted. Set to 0 to\n","                        turn off\n","  -dl, --debug-landmarks\n","                        Draw landmarks on the ouput faces for debugging\n","                        purposes.\n","  -sp, --singleprocess  Don't run extraction in parallel. Will run each part\n","                        of the extraction process separately (one after the\n","                        other) rather than all at the smae time. Useful if\n","                        VRAM is at a premium.\n","  -s, --skip-existing   Skips frames that have already been extracted and\n","                        exist in the alignments file\n","  -sf, --skip-existing-faces\n","                        Skip frames that already have detected faces in the\n","                        alignments file\n","  -ssf, --skip-saving-faces\n","                        Skip saving out the face images\n","\n","Questions and feedback: https://faceswap.dev/forum\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YdvZvvDh7qwr","colab_type":"code","outputId":"c391e14a-6ba3-4db1-b519-f559195d8547","executionInfo":{"status":"ok","timestamp":1590944243473,"user_tz":-330,"elapsed":78514,"user":{"displayName":"Hardi Trivedi","photoUrl":"https://lh5.googleusercontent.com/-KiuyDj-DCbs/AAAAAAAAAAI/AAAAAAAAPbo/R0GSg7b3cbM/s64/photo.jpg","userId":"03163205148644422257"}},"colab":{"base_uri":"https://localhost:8080/","height":487}},"source":["!python faceswap.py extract -i photo/trump -o data/trump"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Setting Faceswap backend to NVIDIA\n","05/31/2020 16:56:24 INFO     Log level set to: INFO\n","05/31/2020 16:56:26 INFO     Output Directory: /content/drive/My Drive/Colab Notebooks/faceswap/data/trump\n","05/31/2020 16:56:27 INFO     Loading Detect from S3Fd plugin...\n","Using TensorFlow backend.\n","05/31/2020 16:56:27 INFO     Loading Align from Fan plugin...\n","05/31/2020 16:56:27 INFO     Loading Mask from Components plugin...\n","05/31/2020 16:56:27 INFO     Loading Mask from Extended plugin...\n","05/31/2020 16:56:27 INFO     Starting, this may take a while...\n","05/31/2020 16:56:27 INFO     Initializing S3FD (Detect)...\n","05/31/2020 16:56:32 INFO     Initialized S3FD (Detect) with batchsize of 4\n","05/31/2020 16:56:32 INFO     Initializing FAN (Align)...\n","05/31/2020 16:56:54 INFO     Initialized FAN (Align) with batchsize of 12\n","05/31/2020 16:56:54 INFO     Initializing Components (Mask)...\n","05/31/2020 16:56:54 INFO     Initialized Components (Mask) with batchsize of 1\n","05/31/2020 16:56:54 INFO     Initializing Extended (Mask)...\n","05/31/2020 16:56:54 INFO     Initialized Extended (Mask) with batchsize of 1\n","Running pass 1 of 1: Extraction: 100% 50/50 [00:23<00:00,  2.11it/s]\n","05/31/2020 16:57:20 INFO     Writing alignments to: '/content/drive/My Drive/Colab Notebooks/faceswap/photo/trump/alignments.fsa'\n","05/31/2020 16:57:21 INFO     -------------------------\n","05/31/2020 16:57:21 INFO     Images found:        50\n","05/31/2020 16:57:21 INFO     Faces detected:      71\n","05/31/2020 16:57:21 INFO     -------------------------\n","05/31/2020 16:57:21 INFO     Note:\n","05/31/2020 16:57:21 INFO     Multiple faces were detected in one or more pictures.\n","05/31/2020 16:57:21 INFO     Double check your results.\n","05/31/2020 16:57:21 INFO     -------------------------\n","05/31/2020 16:57:21 INFO     Process Succesfully Completed. Shutting Down...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Eqq93KtA9erx","colab_type":"code","outputId":"f075ffd1-4575-493c-d63b-19875040e86a","executionInfo":{"status":"ok","timestamp":1591081386472,"user_tz":-330,"elapsed":127983,"user":{"displayName":"Hardi Trivedi","photoUrl":"https://lh5.googleusercontent.com/-KiuyDj-DCbs/AAAAAAAAAAI/AAAAAAAAPbo/R0GSg7b3cbM/s64/photo.jpg","userId":"03163205148644422257"}},"colab":{"base_uri":"https://localhost:8080/","height":487}},"source":["!python faceswap.py extract -i photo/cage -o data/cage"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Setting Faceswap backend to NVIDIA\n","06/02/2020 07:01:57 INFO     Log level set to: INFO\n","06/02/2020 07:02:06 INFO     Output Directory: /content/drive/My Drive/Colab Notebooks/faceswap/data/cage\n","06/02/2020 07:02:07 INFO     Loading Detect from S3Fd plugin...\n","Using TensorFlow backend.\n","06/02/2020 07:02:12 INFO     Loading Align from Fan plugin...\n","06/02/2020 07:02:12 INFO     Loading Mask from Components plugin...\n","06/02/2020 07:02:13 INFO     Loading Mask from Extended plugin...\n","06/02/2020 07:02:13 INFO     Starting, this may take a while...\n","06/02/2020 07:02:13 INFO     Initializing S3FD (Detect)...\n","06/02/2020 07:02:32 INFO     Initialized S3FD (Detect) with batchsize of 4\n","06/02/2020 07:02:32 INFO     Initializing FAN (Align)...\n","06/02/2020 07:02:53 INFO     Initialized FAN (Align) with batchsize of 12\n","06/02/2020 07:02:53 INFO     Initializing Components (Mask)...\n","06/02/2020 07:02:53 INFO     Initialized Components (Mask) with batchsize of 1\n","06/02/2020 07:02:53 INFO     Initializing Extended (Mask)...\n","06/02/2020 07:02:53 INFO     Initialized Extended (Mask) with batchsize of 1\n","Running pass 1 of 1: Extraction: 100% 54/54 [00:09<00:00,  5.85it/s]\n","06/02/2020 07:03:02 INFO     Writing alignments to: '/content/drive/My Drive/Colab Notebooks/faceswap/photo/cage/alignments.fsa'\n","06/02/2020 07:03:03 INFO     -------------------------\n","06/02/2020 07:03:03 INFO     Images found:        54\n","06/02/2020 07:03:03 INFO     Faces detected:      67\n","06/02/2020 07:03:03 INFO     -------------------------\n","06/02/2020 07:03:03 INFO     Note:\n","06/02/2020 07:03:03 INFO     Multiple faces were detected in one or more pictures.\n","06/02/2020 07:03:03 INFO     Double check your results.\n","06/02/2020 07:03:03 INFO     -------------------------\n","06/02/2020 07:03:03 INFO     Process Succesfully Completed. Shutting Down...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EhTLZtbCuu0i","colab_type":"code","outputId":"b9cdad59-c330-4545-961c-e5f3802acda1","executionInfo":{"status":"ok","timestamp":1591101915443,"user_tz":-330,"elapsed":120764,"user":{"displayName":"Hardi Trivedi","photoUrl":"https://lh5.googleusercontent.com/-KiuyDj-DCbs/AAAAAAAAAAI/AAAAAAAAPbo/R0GSg7b3cbM/s64/photo.jpg","userId":"03163205148644422257"}},"colab":{"base_uri":"https://localhost:8080/","height":406}},"source":["!python faceswap.py train -A data/trump -B data/cage -m models "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Setting Faceswap backend to NVIDIA\n","06/02/2020 12:43:15 INFO     Log level set to: INFO\n","Using TensorFlow backend.\n","06/02/2020 12:43:29 INFO     Model A Directory: /content/drive/My Drive/Colab Notebooks/faceswap/data/trump\n","06/02/2020 12:43:29 INFO     Model B Directory: /content/drive/My Drive/Colab Notebooks/faceswap/data/cage\n","06/02/2020 12:43:29 INFO     Training data directory: /content/drive/My Drive/Colab Notebooks/faceswap/models\n","06/02/2020 12:43:29 INFO     ===================================================\n","06/02/2020 12:43:29 INFO       Starting\n","06/02/2020 12:43:29 INFO       Press 'ENTER' to save and quit\n","06/02/2020 12:43:29 INFO       Press 'S' to save model weights immediately\n","06/02/2020 12:43:29 INFO     ===================================================\n","06/02/2020 12:43:30 INFO     Loading data, this may take a while...\n","06/02/2020 12:43:30 INFO     Loading Model from Original plugin...\n","06/02/2020 12:43:47 INFO     Using configuration saved in state file\n","06/02/2020 12:44:08 INFO     Loaded model from disk: '/content/drive/My Drive/Colab Notebooks/faceswap/models'\n","06/02/2020 12:44:08 INFO     Loading Trainer from Original plugin...\n","06/02/2020 12:44:12 INFO     Enabled TensorBoard Logging\n","[12:44:42] [#14608] Loss A: 0.04426, Loss B: 0.04479\n","06/02/2020 12:44:44 INFO     [Saved models] - Average since last save: face_loss_A: 0.04426, face_loss_B: 0.04479\n","[12:45:06] [#14627] Loss A: 0.04614, Loss B: 0.0467406/02/2020 12:45:07 INFO     Exit requested! The trainer will complete its current cycle, save the models and quit (This can take a couple of minutes depending on your training speed). If you want to kill it now, press Ctrl + c\n","[12:45:07] [#14628] Loss A: 0.04547, Loss B: 0.04440\n","06/02/2020 12:45:11 INFO     [Saved models] - Average since last save: face_loss_A: 0.04354, face_loss_B: 0.04423\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CdvBrB4swEZ5","colab_type":"code","outputId":"28204495-06a3-407d-80ca-5ea43ddbef5c","executionInfo":{"status":"ok","timestamp":1591102011265,"user_tz":-330,"elapsed":165232,"user":{"displayName":"Hardi Trivedi","photoUrl":"https://lh5.googleusercontent.com/-KiuyDj-DCbs/AAAAAAAAAAI/AAAAAAAAPbo/R0GSg7b3cbM/s64/photo.jpg","userId":"03163205148644422257"}},"colab":{"base_uri":"https://localhost:8080/","height":370}},"source":["!python faceswap.py convert -i photo/trump -o output -m models"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Setting Faceswap backend to NVIDIA\n","06/02/2020 12:45:15 INFO     Log level set to: INFO\n","Using TensorFlow backend.\n","06/02/2020 12:45:25 INFO     Reading alignments from: '/content/drive/My Drive/Colab Notebooks/faceswap/photo/trump/alignments.fsa'\n","06/02/2020 12:45:26 INFO     Loading Writer from Opencv plugin...\n","06/02/2020 12:45:39 INFO     Loading Model from Original plugin...\n","06/02/2020 12:45:39 INFO     Using configuration saved in state file\n","06/02/2020 12:45:52 INFO     Loaded model from disk: '/content/drive/My Drive/Colab Notebooks/faceswap/models'\n","06/02/2020 12:45:52 INFO     Loading Mask from Box_Blend plugin...\n","06/02/2020 12:45:54 INFO     Loading Mask from Mask_Blend plugin...\n","06/02/2020 12:45:55 INFO     Loading Color from Avg_Color plugin...\n","Converting: 100% 50/50 [01:08<00:00,  1.36s/it]\n","06/02/2020 12:46:47 INFO     -------------------------\n","06/02/2020 12:46:47 INFO     Images found:        50\n","06/02/2020 12:46:47 INFO     Faces detected:      71\n","06/02/2020 12:46:47 INFO     -------------------------\n","06/02/2020 12:46:47 INFO     Note:\n","06/02/2020 12:46:47 INFO     Multiple faces were detected in one or more pictures.\n","06/02/2020 12:46:47 INFO     Double check your results.\n","06/02/2020 12:46:47 INFO     -------------------------\n","06/02/2020 12:46:47 INFO     Process Succesfully Completed. Shutting Down...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qsaoa3fGvZkS","colab_type":"code","outputId":"d962dc08-456f-4901-da4b-57b92194c85d","executionInfo":{"status":"ok","timestamp":1590944423095,"user_tz":-330,"elapsed":230575,"user":{"displayName":"Hardi Trivedi","photoUrl":"https://lh5.googleusercontent.com/-KiuyDj-DCbs/AAAAAAAAAAI/AAAAAAAAPbo/R0GSg7b3cbM/s64/photo.jpg","userId":"03163205148644422257"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python tools.py effmpeg -h"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Setting Faceswap backend to NVIDIA\n","Please backup your data and/or test the tool you want to use with a smaller data set to make sure you understand how it works.\n","usage: tools.py effmpeg [-h] [-C CONFIGFILE] [-L {INFO,VERBOSE,DEBUG,TRACE}]\n","                        [-LF LOGFILE]\n","                        [-a {extract,gen-vid,get-fps,get-info,mux-audio,rescale,rotate,slice}]\n","                        -i INPUT [-o OUTPUT] [-r REF_VID] [-fps FPS]\n","                        [-ef {.bmp,.jpeg,.jpg,.png,.tif,.tiff}] [-s START]\n","                        [-e END] [-d DURATION] [-m]\n","                        [-tr {0, 90CounterClockwise&VerticalFlip),(1, 90Clockwise),(2, 90CounterClockwise),(3, 90Clockwise&VerticalFlip}]\n","                        [-de DEGREES] [-sc SCALE] [-q] [-v]\n","\n","This command allows you to easily execute common ffmpeg tasks.\n","\n","optional arguments:\n","  -h, --help            show this help message and exit\n","  -C CONFIGFILE, --configfile CONFIGFILE\n","                        Optionally overide the saved config with the path to a\n","                        custom config file.\n","  -L {INFO,VERBOSE,DEBUG,TRACE}, --loglevel {INFO,VERBOSE,DEBUG,TRACE}\n","                        Log level. Stick with INFO or VERBOSE unless you need\n","                        to file an error report. Be careful with TRACE as it\n","                        will generate a lot of data\n","  -LF LOGFILE, --logfile LOGFILE\n","                        Path to store the logfile. Leave blank to store in the\n","                        faceswap folder\n","  -a {extract,gen-vid,get-fps,get-info,mux-audio,rescale,rotate,slice}, --action {extract,gen-vid,get-fps,get-info,mux-audio,rescale,rotate,slice}\n","                        Choose which action you want ffmpeg ffmpeg to do.\n","                          - 'extract': turns videos into images\n","                          - 'gen-vid': turns images into videos\n","                          - 'get-fps' returns the chosen video's fps.\n","                          - 'get-info' returns information about a video.\n","                          - 'mux-audio' add audio from one video to another.\n","                          - 'rescale' resize video.\n","                          - 'rotate' rotate video.\n","                          - 'slice' cuts a portion of the video into a\n","                            separate video file.\n","  -i INPUT, --input INPUT\n","                        Input file.\n","  -o OUTPUT, --output OUTPUT\n","                        Output file. If no output is specified then: if the\n","                        output is meant to be a video then a video called\n","                        'out.mkv' will be created in the input directory; if\n","                        the output is meant to be a directory then a directory\n","                        called 'out' will be created inside the input\n","                        directory.Note: the chosen output file extension will\n","                        determine the file encoding.\n","  -r REF_VID, --reference-video REF_VID\n","                        Path to reference video if 'input' was not a video.\n","  -fps FPS, --fps FPS   Provide video fps. Can be an integer, float or\n","                        fraction. Negative values will make the program try to\n","                        get the fps from the input or reference videos.\n","  -ef {.bmp,.jpeg,.jpg,.png,.tif,.tiff}, --extract-filetype {.bmp,.jpeg,.jpg,.png,.tif,.tiff}\n","                        Image format that extracted images should be saved as.\n","                        '.bmp' will offer the fastest extraction speed, but\n","                        will take the most storage space. '.png' will be\n","                        slower but will take less storage.\n","  -s START, --start START\n","                        Enter the start time from which an action is to be\n","                        applied. Default: 00:00:00, in HH:MM:SS format. You\n","                        can also enter the time with or without the colons,\n","                        e.g. 00:0000 or 026010.\n","  -e END, --end END     Enter the end time to which an action is to be\n","                        applied. If both an end time and duration are set,\n","                        then the end time will be used and the duration will\n","                        be ignored. Default: 00:00:00, in HH:MM:SS.\n","  -d DURATION, --duration DURATION\n","                        Enter the duration of the chosen action, for example\n","                        if you enter 00:00:10 for slice, then the first 10\n","                        seconds after and including the start time will be cut\n","                        out into a new video. Default: 00:00:00, in HH:MM:SS\n","                        format. You can also enter the time with or without\n","                        the colons, e.g. 00:0000 or 026010.\n","  -m, --mux-audio       Mux the audio from the reference video into the input\n","                        video. This option is only used for the 'gen-vid'\n","                        action. 'mux-audio' action has this turned on\n","                        implicitly.\n","  -tr {(0, 90CounterClockwise&VerticalFlip),(1, 90Clockwise),(2, 90CounterClockwise),(3, 90Clockwise&VerticalFlip)}, --transpose {(0, 90CounterClockwise&VerticalFlip),(1, 90Clockwise),(2, 90CounterClockwise),(3, 90Clockwise&VerticalFlip)}\n","                        Transpose the video. If transpose is set, then degrees\n","                        will be ignored. For cli you can enter either the\n","                        number or the long command name, e.g. to use (1,\n","                        90Clockwise) -tr 1 or -tr 90Clockwise\n","  -de DEGREES, --degrees DEGREES\n","                        Rotate the video clockwise by the given number of\n","                        degrees.\n","  -sc SCALE, --scale SCALE\n","                        Set the new resolution scale if the chosen action is\n","                        'rescale'.\n","  -q, --quiet           Reduces output verbosity so that only serious errors\n","                        are printed. If both quiet and verbose are set,\n","                        verbose will override quiet.\n","  -v, --verbose         Increases output verbosity. If both quiet and verbose\n","                        are set, verbose will override quiet.\n","\n","Questions and feedback: https://faceswap.dev/forum\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZuhfYuCoG_gK","colab_type":"code","outputId":"df99c136-27bd-4320-e976-995b95a28a58","executionInfo":{"status":"ok","timestamp":1591081535620,"user_tz":-330,"elapsed":215432,"user":{"displayName":"Hardi Trivedi","photoUrl":"https://lh5.googleusercontent.com/-KiuyDj-DCbs/AAAAAAAAAAI/AAAAAAAAPbo/R0GSg7b3cbM/s64/photo.jpg","userId":"03163205148644422257"}},"colab":{"base_uri":"https://localhost:8080/","height":420}},"source":["!python faceswap.py extract -i video/trumpvideo.mp4 -o datavideo"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Setting Faceswap backend to NVIDIA\n","06/02/2020 07:04:22 INFO     Log level set to: INFO\n","06/02/2020 07:04:23 INFO     Output Directory: /content/drive/My Drive/Colab Notebooks/faceswap/datavideo\n","06/02/2020 07:04:24 INFO     Loading Detect from S3Fd plugin...\n","Using TensorFlow backend.\n","06/02/2020 07:04:24 INFO     Loading Align from Fan plugin...\n","06/02/2020 07:04:24 INFO     Loading Mask from Components plugin...\n","06/02/2020 07:04:24 INFO     Loading Mask from Extended plugin...\n","06/02/2020 07:04:24 INFO     Starting, this may take a while...\n","06/02/2020 07:04:24 INFO     Initializing S3FD (Detect)...\n","06/02/2020 07:04:26 INFO     Initialized S3FD (Detect) with batchsize of 4\n","06/02/2020 07:04:26 INFO     Initializing FAN (Align)...\n","06/02/2020 07:04:43 INFO     Initialized FAN (Align) with batchsize of 12\n","06/02/2020 07:04:43 INFO     Initializing Components (Mask)...\n","06/02/2020 07:04:43 INFO     Initialized Components (Mask) with batchsize of 1\n","06/02/2020 07:04:43 INFO     Initializing Extended (Mask)...\n","06/02/2020 07:04:43 INFO     Initialized Extended (Mask) with batchsize of 1\n","Running pass 1 of 1: Extraction: 100% 595/595 [00:47<00:00, 12.53it/s]\n","06/02/2020 07:05:31 INFO     Writing alignments to: '/content/drive/My Drive/Colab Notebooks/faceswap/video/trumpvideo_alignments.fsa'\n","06/02/2020 07:05:32 INFO     -------------------------\n","06/02/2020 07:05:32 INFO     Images found:        595\n","06/02/2020 07:05:32 INFO     Faces detected:      595\n","06/02/2020 07:05:32 INFO     -------------------------\n","06/02/2020 07:05:32 INFO     Process Succesfully Completed. Shutting Down...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l6com-G9Ie4m","colab_type":"code","outputId":"5a5b6cb7-3534-453a-9c3c-829a980a646c","executionInfo":{"status":"ok","timestamp":1591081577332,"user_tz":-330,"elapsed":250251,"user":{"displayName":"Hardi Trivedi","photoUrl":"https://lh5.googleusercontent.com/-KiuyDj-DCbs/AAAAAAAAAAI/AAAAAAAAPbo/R0GSg7b3cbM/s64/photo.jpg","userId":"03163205148644422257"}},"colab":{"base_uri":"https://localhost:8080/","height":406}},"source":["!python faceswap.py train -A datavideo -B data/cage -m modelsvideo"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Setting Faceswap backend to NVIDIA\n","06/02/2020 07:05:35 INFO     Log level set to: INFO\n","Using TensorFlow backend.\n","06/02/2020 07:05:36 INFO     Model A Directory: /content/drive/My Drive/Colab Notebooks/faceswap/datavideo\n","06/02/2020 07:05:36 INFO     Model B Directory: /content/drive/My Drive/Colab Notebooks/faceswap/data/cage\n","06/02/2020 07:05:36 INFO     Training data directory: /content/drive/My Drive/Colab Notebooks/faceswap/modelsvideo\n","06/02/2020 07:05:36 INFO     ===================================================\n","06/02/2020 07:05:36 INFO       Starting\n","06/02/2020 07:05:36 INFO       Press 'ENTER' to save and quit\n","06/02/2020 07:05:36 INFO       Press 'S' to save model weights immediately\n","06/02/2020 07:05:36 INFO     ===================================================\n","06/02/2020 07:05:37 INFO     Loading data, this may take a while...\n","06/02/2020 07:05:37 INFO     Loading Model from Original plugin...\n","06/02/2020 07:05:38 INFO     Using configuration saved in state file\n","06/02/2020 07:05:46 INFO     Loaded model from disk: '/content/drive/My Drive/Colab Notebooks/faceswap/modelsvideo'\n","06/02/2020 07:05:47 INFO     Loading Trainer from Original plugin...\n","06/02/2020 07:05:48 INFO     Enabled TensorBoard Logging\n","[07:05:57] [#10876] Loss A: 0.03341, Loss B: 0.05349\n","06/02/2020 07:05:59 INFO     [Saved models] - Average since last save: face_loss_A: 0.03341, face_loss_B: 0.05349\n","[07:06:12] [#10893] Loss A: 0.03386, Loss B: 0.0529306/02/2020 07:06:12 INFO     Exit requested! The trainer will complete its current cycle, save the models and quit (This can take a couple of minutes depending on your training speed). If you want to kill it now, press Ctrl + c\n","[07:06:13] [#10894] Loss A: 0.03289, Loss B: 0.04987\n","06/02/2020 07:06:14 INFO     [Saved models] - Average since last save: face_loss_A: 0.03218, face_loss_B: 0.04809\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kkaUNHZOliTF","colab_type":"code","outputId":"51f03415-c9fa-4688-9c31-c660b2c7d4ab","executionInfo":{"status":"ok","timestamp":1591081666311,"user_tz":-330,"elapsed":336883,"user":{"displayName":"Hardi Trivedi","photoUrl":"https://lh5.googleusercontent.com/-KiuyDj-DCbs/AAAAAAAAAAI/AAAAAAAAPbo/R0GSg7b3cbM/s64/photo.jpg","userId":"03163205148644422257"}},"colab":{"base_uri":"https://localhost:8080/","height":336}},"source":["!python faceswap.py convert -i video/trumpvideo.mp4 -o outputvideo -m \"modelsvideo\" -w ffmpeg"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Setting Faceswap backend to NVIDIA\n","06/02/2020 07:06:16 INFO     Log level set to: INFO\n","Using TensorFlow backend.\n","06/02/2020 07:06:19 INFO     Reading alignments from: '/content/drive/My Drive/Colab Notebooks/faceswap/video/trumpvideo_alignments.fsa'\n","06/02/2020 07:06:19 INFO     Loading Writer from Ffmpeg plugin...\n","06/02/2020 07:06:24 INFO     Loading Model from Original plugin...\n","06/02/2020 07:06:24 INFO     Using configuration saved in state file\n","06/02/2020 07:06:27 INFO     Loaded model from disk: '/content/drive/My Drive/Colab Notebooks/faceswap/modelsvideo'\n","06/02/2020 07:06:27 INFO     Loading Mask from Box_Blend plugin...\n","06/02/2020 07:06:28 INFO     Loading Mask from Mask_Blend plugin...\n","06/02/2020 07:06:28 INFO     Loading Color from Avg_Color plugin...\n","06/02/2020 07:06:29 INFO     Outputting to: '/content/drive/My Drive/Colab Notebooks/faceswap/outputvideo/trumpvideo_converted.mp4'\n","Converting: 100% 595/595 [01:16<00:00,  7.73it/s]\n","06/02/2020 07:07:42 INFO     Muxing Audio...\n","06/02/2020 07:07:43 INFO     -------------------------\n","06/02/2020 07:07:43 INFO     Images found:        595\n","06/02/2020 07:07:43 INFO     Faces detected:      595\n","06/02/2020 07:07:43 INFO     -------------------------\n","06/02/2020 07:07:43 INFO     Process Succesfully Completed. Shutting Down...\n"],"name":"stdout"}]}]}